{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-play-scraper in c:\\users\\nugro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sastrawi in c:\\users\\nugro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nugro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nugro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install google-play-scraper\n",
    " \n",
    "# Mengimpor pustaka google_play_scraper untuk mengakses ulasan dan informasi aplikasi dari Google Play Store.\n",
    "from google_play_scraper import app, reviews, Sort, reviews_all\n",
    " \n",
    "import pandas as pd  # Pandas untuk manipulasi dan analisis data\n",
    "pd.options.mode.chained_assignment = None  # Menonaktifkan peringatan chaining\n",
    "import numpy as np  # NumPy untuk komputasi numerik\n",
    "seed = 0\n",
    "np.random.seed(seed)  # Mengatur seed untuk reproduktibilitas\n",
    "import matplotlib.pyplot as plt  # Matplotlib untuk visualisasi data\n",
    "import seaborn as sns  # Seaborn untuk visualisasi data statistik, mengatur gaya visualisasi\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "import datetime as dt  # Manipulasi data waktu dan tanggal\n",
    "import re  # Modul untuk bekerja dengan ekspresi reguler\n",
    "import string  # Berisi konstanta string, seperti tanda baca\n",
    "from nltk.tokenize import word_tokenize  # Tokenisasi teks\n",
    "from nltk.corpus import stopwords  # Daftar kata-kata berhenti dalam teks\n",
    " \n",
    "%pip install sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory  # Stemming (penghilangan imbuhan kata) dalam bahasa Indonesia\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory  # Menghapus kata-kata berhenti dalam bahasa Indonesia\n",
    " \n",
    "from wordcloud import WordCloud  # Membuat visualisasi berbentuk awan kata (word cloud) dari teks\n",
    " \n",
    "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
    "nltk.download('punkt')  # Mengunduh dataset yang diperlukan untuk tokenisasi teks.\n",
    "nltk.download('stopwords')  # Mengunduh dataset yang berisi daftar kata-kata berhenti (stopwords) dalam berbagai bahasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil semua ulasan dari aplikasi dengan ID 'com.byu.id' di Google Play Store.\n",
    "# Proses scraping mungkin memerlukan beberapa saat tergantung pada jumlah ulasan yang ada.\n",
    "scrapreview = reviews_all(\n",
    "    'com.byu.id',          # ID aplikasi\n",
    "    lang='id',             # Bahasa ulasan (default: 'en')\n",
    "    country='id',          # Negara (default: 'us')\n",
    "    sort=Sort.MOST_RELEVANT, # Urutan ulasan (default: Sort.MOST_RELEVANT)\n",
    "    count=1000             # Jumlah maksimum ulasan yang ingin diambil\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan ulasan dalam file CSV\n",
    "import csv\n",
    " \n",
    "with open('ulasan_aplikasi.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Review'])  # Menulis header kolom\n",
    "    for review in scrapreview:\n",
    "        writer.writerow([review['content']])  # Menulis konten ulasan ke dalam file CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_reviews_df = pd.DataFrame(scrapreview)\n",
    "app_reviews_df.shape\n",
    "app_reviews_df.head()\n",
    "app_reviews_df.to_csv('ulasan_aplikasi.csv', index=False)\n",
    " \n",
    "# Membuat DataFrame dari hasil scrapreview\n",
    "app_reviews_df = pd.DataFrame(scrapreview)\n",
    " \n",
    "# Menghitung jumlah baris dan kolom dalam DataFrame\n",
    "jumlah_ulasan, jumlah_kolom = app_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fa741b7-03fe-4fe8-b246-3e83e2d750b9</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dulu By.U cukup stabil, tapi sekarang sering l...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1.61.0</td>\n",
       "      <td>2025-03-30 06:24:47</td>\n",
       "      <td>Hai kak Yin, Sebelumnya mohon maaf banget, ata...</td>\n",
       "      <td>2025-03-30 09:46:55</td>\n",
       "      <td>1.61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1afe8f1c-7b6c-463f-95d2-f5868d60355e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>kecewa berat dengan pengalaman saya membeli pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1.61.0</td>\n",
       "      <td>2025-03-22 12:35:48</td>\n",
       "      <td>Hi, Kak. Maaf banget jadi bikin gak nyaman. Ni...</td>\n",
       "      <td>2025-03-22 22:14:22</td>\n",
       "      <td>1.61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>da82c03a-fd4a-40c9-b69e-cf8666f4639e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>kecewa berat dengan pengalaman saya membeli pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>183</td>\n",
       "      <td>1.61.0</td>\n",
       "      <td>2025-03-19 04:09:45</td>\n",
       "      <td>Hi, Kak. Maaf banget jadi bikin gak nyaman. Ni...</td>\n",
       "      <td>2025-03-19 09:40:39</td>\n",
       "      <td>1.61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b728ecf9-d9b6-4587-914e-3b8fc6847cb7</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>aplikasi ini sudah baik, namun ada sedikit fit...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.61.0</td>\n",
       "      <td>2025-03-30 11:43:00</td>\n",
       "      <td>Hai Kak. Makasih feedback nya. Nindy pasti bak...</td>\n",
       "      <td>2025-03-30 14:17:23</td>\n",
       "      <td>1.61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195a4528-1f7f-4d6a-8f60-c0bd5f917408</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>over all bagus sih mulai dri sinyal, pilihan k...</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>1.61.0</td>\n",
       "      <td>2025-03-21 00:05:09</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  4fa741b7-03fe-4fe8-b246-3e83e2d750b9  Pengguna Google   \n",
       "1  1afe8f1c-7b6c-463f-95d2-f5868d60355e  Pengguna Google   \n",
       "2  da82c03a-fd4a-40c9-b69e-cf8666f4639e  Pengguna Google   \n",
       "3  b728ecf9-d9b6-4587-914e-3b8fc6847cb7  Pengguna Google   \n",
       "4  195a4528-1f7f-4d6a-8f60-c0bd5f917408  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Dulu By.U cukup stabil, tapi sekarang sering l...      1             21   \n",
       "1  kecewa berat dengan pengalaman saya membeli pa...      1            123   \n",
       "2  kecewa berat dengan pengalaman saya membeli pa...      1            183   \n",
       "3  aplikasi ini sudah baik, namun ada sedikit fit...      3              1   \n",
       "4  over all bagus sih mulai dri sinyal, pilihan k...      5            172   \n",
       "\n",
       "  reviewCreatedVersion                  at  \\\n",
       "0               1.61.0 2025-03-30 06:24:47   \n",
       "1               1.61.0 2025-03-22 12:35:48   \n",
       "2               1.61.0 2025-03-19 04:09:45   \n",
       "3               1.61.0 2025-03-30 11:43:00   \n",
       "4               1.61.0 2025-03-21 00:05:09   \n",
       "\n",
       "                                        replyContent           repliedAt  \\\n",
       "0  Hai kak Yin, Sebelumnya mohon maaf banget, ata... 2025-03-30 09:46:55   \n",
       "1  Hi, Kak. Maaf banget jadi bikin gak nyaman. Ni... 2025-03-22 22:14:22   \n",
       "2  Hi, Kak. Maaf banget jadi bikin gak nyaman. Ni... 2025-03-19 09:40:39   \n",
       "3  Hai Kak. Makasih feedback nya. Nindy pasti bak... 2025-03-30 14:17:23   \n",
       "4                                               None                 NaT   \n",
       "\n",
       "  appVersion  \n",
       "0     1.61.0  \n",
       "1     1.61.0  \n",
       "2     1.61.0  \n",
       "3     1.61.0  \n",
       "4     1.61.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menampilkan lima baris pertama dari DataFrame app_reviews_df\n",
    "app_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112500 entries, 0 to 112499\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   reviewId              112500 non-null  object        \n",
      " 1   userName              112500 non-null  object        \n",
      " 2   userImage             112500 non-null  object        \n",
      " 3   content               112500 non-null  object        \n",
      " 4   score                 112500 non-null  int64         \n",
      " 5   thumbsUpCount         112500 non-null  int64         \n",
      " 6   reviewCreatedVersion  94264 non-null   object        \n",
      " 7   at                    112500 non-null  datetime64[ns]\n",
      " 8   replyContent          103492 non-null  object        \n",
      " 9   repliedAt             103492 non-null  datetime64[ns]\n",
      " 10  appVersion            94264 non-null   object        \n",
      "dtypes: datetime64[ns](2), int64(2), object(7)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan informasi tentang DataFrame app_reviews_df\n",
    "app_reviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat DataFrame baru (clean_df) dengan menghapus baris yang memiliki nilai yang hilang (NaN) dari app_reviews_df\n",
    "clean_df = app_reviews_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus baris duplikat dari DataFrame clean_df\n",
    "clean_df = clean_df.drop_duplicates()\n",
    " \n",
    "# Menghitung jumlah baris dan kolom dalam DataFrame clean_df setelah menghapus duplikat\n",
    "jumlah_ulasan_setelah_hapus_duplikat, jumlah_kolom_setelah_hapus_duplikat = clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 86208 entries, 0 to 112499\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   reviewId              86208 non-null  object        \n",
      " 1   userName              86208 non-null  object        \n",
      " 2   userImage             86208 non-null  object        \n",
      " 3   content               86208 non-null  object        \n",
      " 4   score                 86208 non-null  int64         \n",
      " 5   thumbsUpCount         86208 non-null  int64         \n",
      " 6   reviewCreatedVersion  86208 non-null  object        \n",
      " 7   at                    86208 non-null  datetime64[ns]\n",
      " 8   replyContent          86208 non-null  object        \n",
      " 9   repliedAt             86208 non-null  datetime64[ns]\n",
      " 10  appVersion            86208 non-null  object        \n",
      "dtypes: datetime64[ns](2), int64(2), object(7)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    " \n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    " \n",
    "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    " \n",
    "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    " \n",
    "def filteringText(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    " \n",
    "def stemmingText(text): # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
    "    # Membuat objek stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    " \n",
    "    # Memecah teks menjadi daftar kata\n",
    "    words = text.split()\n",
    " \n",
    "    # Menerapkan stemming pada setiap kata dalam daftar\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    " \n",
    "    # Menggabungkan kata-kata yang telah distem\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    " \n",
    "    return stemmed_text\n",
    " \n",
    "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "slangwords = {\n",
    "    \"@\": \"di\",\n",
    "    \"abis\": \"habis\",\n",
    "    \"wtb\": \"beli\",\n",
    "    \"masi\": \"masih\",\n",
    "    \"wts\": \"jual\",\n",
    "    \"wtt\": \"tukar\",\n",
    "    \"bgt\": \"banget\",\n",
    "    \"maks\": \"maksimal\"\n",
    "}\n",
    "\n",
    "def fix_slangwords(text):\n",
    "    words = text.split()\n",
    "    fixed_words = []\n",
    " \n",
    "    for word in words:\n",
    "        if word.lower() in slangwords:\n",
    "            fixed_words.append(slangwords[word.lower()])\n",
    "        else:\n",
    "            fixed_words.append(word)\n",
    " \n",
    "    fixed_text = ' '.join(fixed_words)\n",
    "    return fixed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membersihkan teks dan menyimpannya di kolom 'text_clean'\n",
    "clean_df['text_clean'] = clean_df['content'].apply(cleaningText)\n",
    " \n",
    "# Mengubah huruf dalam teks menjadi huruf kecil dan menyimpannya di 'text_casefoldingText'\n",
    "clean_df['text_casefoldingText'] = clean_df['text_clean'].apply(casefoldingText)\n",
    " \n",
    "# Mengganti kata-kata slang dengan kata-kata standar dan menyimpannya di 'text_slangwords'\n",
    "clean_df['text_slangwords'] = clean_df['text_casefoldingText'].apply(fix_slangwords)\n",
    " \n",
    "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tokenizingText'\n",
    "clean_df['text_tokenizingText'] = clean_df['text_slangwords'].apply(tokenizingText)\n",
    " \n",
    "# Menghapus kata-kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
    "clean_df['text_stopword'] = clean_df['text_tokenizingText'].apply(filteringText)\n",
    " \n",
    "# Menggabungkan token-token menjadi kalimat dan menyimpannya di 'text_akhir'\n",
    "clean_df['text_akhir'] = clean_df['text_stopword'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pelabelan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    " \n",
    "# Membaca data kamus kata-kata positif dari GitHub\n",
    "lexicon_positive = dict()\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata positif dan skornya ke dalam kamus lexicon_positive\n",
    "else:\n",
    "    print(\"Failed to fetch positive lexicon data\")\n",
    " \n",
    "# Membaca data kamus kata-kata negatif dari GitHub\n",
    "lexicon_negative = dict()\n",
    " \n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "# Mengirim permintaan HTTP untuk mendapatkan file CSV dari GitHub\n",
    " \n",
    "if response.status_code == 200:\n",
    "    # Jika permintaan berhasil\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    # Membaca teks respons sebagai file CSV menggunakan pembaca CSV dengan pemisah koma\n",
    " \n",
    "    for row in reader:\n",
    "        # Mengulangi setiap baris dalam file CSV\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "        # Menambahkan kata-kata negatif dan skornya dalam kamus lexicon_negative\n",
    "else:\n",
    "    print(\"Failed to fetch negative lexicon data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menentukan polaritas sentimen dari tweet\n",
    " \n",
    "def sentiment_analysis_lexicon_indonesia(text):\n",
    "    #for word in text:\n",
    " \n",
    "    score = 0\n",
    "    # Inisialisasi skor sentimen ke 0\n",
    " \n",
    "    for word in text:\n",
    "        # Mengulangi setiap kata dalam teks\n",
    " \n",
    "        if (word in lexicon_positive):\n",
    "            score = score + lexicon_positive[word]\n",
    "            # Jika kata ada dalam kamus positif, tambahkan skornya ke skor sentimen\n",
    " \n",
    "    for word in text:\n",
    "        # Mengulangi setiap kata dalam teks (sekali lagi)\n",
    " \n",
    "        if (word in lexicon_negative):\n",
    "            score = score + lexicon_negative[word]\n",
    "            # Jika kata ada dalam kamus negatif, kurangkan skornya dari skor sentimen\n",
    " \n",
    "    polarity=''\n",
    "    # Inisialisasi variabel polaritas\n",
    " \n",
    "    if (score >= 0):\n",
    "        polarity = 'positive'\n",
    "        # Jika skor sentimen lebih besar atau sama dengan 0, maka polaritas adalah positif\n",
    "    elif (score < 0):\n",
    "        polarity = 'negative'\n",
    "        # Jika skor sentimen kurang dari 0, maka polaritas adalah negatif\n",
    " \n",
    "    # else:\n",
    "    #     polarity = 'neutral'\n",
    "    # Ini adalah bagian yang bisa digunakan untuk menentukan polaritas netral jika diperlukan\n",
    " \n",
    "    return score, polarity\n",
    "    # Mengembalikan skor sentimen dan polaritas teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "negative    43697\n",
      "positive    42511\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = clean_df['text_stopword'].apply(sentiment_analysis_lexicon_indonesia)\n",
    "results = list(zip(*results))\n",
    "clean_df['polarity_score'] = results[0]\n",
    "clean_df['polarity'] = results[1]\n",
    "print(clean_df['polarity'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
