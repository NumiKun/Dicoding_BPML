{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "iDGyVPEEGzBe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bYIQcBOHGtNj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read Dataset"
      ],
      "metadata": {
        "id": "ofMMz1qKHCiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url= 'https://raw.githubusercontent.com/natashayulian/diamond_dataset/master/diamonds.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "KEk9KIb2HDzR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting"
      ],
      "metadata": {
        "id": "7eX3dEbVHKkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.2)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "print(len(train), 'train examples')\n",
        "print(len(val), 'validation examples')\n",
        "print(len(test), 'test examples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJk8gjlPHL82",
        "outputId": "5e06c123-dd45-4abd-9615-ce1266588979"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34521 train examples\n",
            "8631 validation examples\n",
            "10788 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Membuat kolom target\n",
        "# 0 = low; 1 = high\n",
        "df['target'] = np.where(df['price'] <= 1000, 0, 1)\n",
        "# Drop un-used columns.\n",
        "df = df.drop(columns=['price'])"
      ],
      "metadata": {
        "id": "Gbn-lcJyHOk8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Membungkus Dataframe"
      ],
      "metadata": {
        "id": "hpb6kab5HXbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bungkus dataframe dengan tf.data agar memungkinkan untuk menggunakan feature column sebagai jembatan dari dataframe menjadi fitur yang digunakan untuk train model. Jika file CSV nya sangat besar, kita harus menggunakan tf.data untuk membaca file tersebut dari harddisk."
      ],
      "metadata": {
        "id": "ZziehdUmHcOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cara untuk membuat dataset tf.data dari pandas dataframe\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = df.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds\n",
        "batch_size = 10 #bath ukuran kecil untuk demonstrasi\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Iwx-f506HWrZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Column"
      ],
      "metadata": {
        "id": "RLHP_QX6H0Ez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numeric Column\n",
        "Numeric column merupakan jenis feature column yang paling sederhana dan digunakan untuk merepresentasikan sebuah fitur dengan value yang apa adanya. Masukkan ke TensorFlow harus berupa angka dan numeric column sudah merupakan angka sehingga tidak perlu diubah lagi."
      ],
      "metadata": {
        "id": "EHSaeiJgINj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch = next(iter(train_ds))[0]\n",
        "def demo(feature_column):\n",
        "  feature_layer = layers.DenseFeatures(feature_column)\n",
        "  print(feature_layer(example_batch).numpy())"
      ],
      "metadata": {
        "id": "U3a3Y7jeIVgm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#numeric column\n",
        "carat = feature_column.numeric_column('carat')\n",
        "demo(carat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "Gch3FWypJVG3",
        "outputId": "f068eb77-10b2-4fa4-b3b4-74ab553b08bd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c29d2b2577d9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#numeric column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcarat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumeric_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'carat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b814fbb70f95>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(feature_column)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfeature_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bucketized Column\n",
        "Terkadang kita memiliki dataset numerik yang memiliki value beragam dengan range cukup jauh. Daripada memasukkan setiap value ke dalam numeric column, kita dapat menggunakan bucketized column untuk membagi value-value tersebut."
      ],
      "metadata": {
        "id": "TfA3xYdxJaWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bucketized column\n",
        "carat = feature_column.numeric_column('carat')\n",
        "carat_buckets = feature_column.bucketized_column(carat, boundaries=[1, 2])\n",
        "demo(carat_buckets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "8nuTDYR0Ja4c",
        "outputId": "f6874eac-7180-4de1-99d1-f4c37b69587e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8613cb3b1b19>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcarat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumeric_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'carat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcarat_buckets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbucketized_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundaries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarat_buckets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b814fbb70f95>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(feature_column)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfeature_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorical Column\n",
        "Kita tidak dapat memasukkan value String ke dalam TensorFlow. Oleh karena itu, categorical column digunakan untuk mengubah value String pada dataset (pada dataset ini contohnya cut dan clarity) menjadi angka."
      ],
      "metadata": {
        "id": "kBb8dlrjJqrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#categorical\n",
        "color_type = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'color', ['E', 'I','J','D','H', 'G','F'])\n",
        "\n",
        "color_type_one_hot = feature_column.indicator_column(color_type)\n",
        "demo(color_type_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "8rdvtZy-Js5v",
        "outputId": "66bae2ba-e5fe-4480-ff0f-ff40284c687b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-81471e5cd9ea>:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-23-81471e5cd9ea>:5: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-81471e5cd9ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcolor_type_one_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicator_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_type_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b814fbb70f95>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(feature_column)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexample_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfeature_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Embedding Column\n",
        "Jika kita memiliki banyak value dalam satu categorical column, lalu jenis value tersebut dapat bertambah seiring dengan berjalannya waktu, data tersebut menjadi tidak cocok jika hanya direpresentasikan dengan nilai 0 atau 1 seperti categorical column. Embedding column merepresentasikan satu categorical column dengan nilai yang beragam."
      ],
      "metadata": {
        "id": "Tk6hILzxJxPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding\n",
        "clarity = feature_column.categorical_column_with_vocabulary_list(\n",
        "      'clarity', df.clarity.unique())\n",
        "clarity_embedding = feature_column.embedding_column(clarity, dimension=6)\n",
        "demo(clarity_embedding)"
      ],
      "metadata": {
        "id": "iCsTJ6MRJ00t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hashed Feature Column\n",
        "Hashed feature column merupakan cara alternatif untuk merepresentasikan categorical column yang memiliki banyak jenis value. Kita dapat menentukan jumlah hash_buckets jauh lebih sedikit dari jumlah kategori yang sebenarnya untuk menghemat tempat."
      ],
      "metadata": {
        "id": "XxREdHG0J6d3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hashed feature\n",
        "clarity_hashed = feature_column.categorical_column_with_hash_bucket(\n",
        "      'clarity', hash_bucket_size=5)\n",
        "demo(feature_column.indicator_column(clarity_hashed))"
      ],
      "metadata": {
        "id": "0iN74nk8J8mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Crossed Feature Column\n",
        "Crossed feature column menggabungkan banyak feature column menjadi satu feature column. Crossed feature column membuat column feature baru yang memungkinkan model untuk mempelajari weight berbeda untuk setiap kombinasi dari column feature."
      ],
      "metadata": {
        "id": "Hex2AozKKA0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cross feature\n",
        "#data yang di cross harus berupa string, categorical, atau bucketized\n",
        "crossed_feature = feature_column.crossed_column([carat_buckets, color_type],\n",
        "                                                hash_bucket_size=10)\n",
        "demo(feature_column.indicator_column(crossed_feature))"
      ],
      "metadata": {
        "id": "ZbX0P70eKEHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Membuat Feature Layer"
      ],
      "metadata": {
        "id": "hF938hMOKKPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pilih feature column mana yang akan digunakan\n",
        "feature_columns = []\n",
        "# numeric column\n",
        "for header in ['carat', 'depth', 'x', 'y', 'z']:\n",
        "  feature_columns.append(feature_column.numeric_column(header))\n",
        "\n",
        "#membuat feature layer\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
        "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "wuJk6QHyKL8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "-oTAuGB2KPTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create, compile, and train the model\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dropout(.1),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=10)"
      ],
      "metadata": {
        "id": "9zW5NIPWKQsi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}